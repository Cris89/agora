\chapter*{Abstract}

\lettrine{C}{}\textit{ompute} and data intensive research problems, such as universe or microbiological studies, are pushing High Performance Computing architectures to achieve, in 2022, the Exascale level, that is the capability to process a billion billion calculations per second.

These applications manage huge input datasets and they are characterized by multiple parameters that influence execution. Given that power consumption issues and energy efficiency have become essential, there exist various techniques that try to improve these aspects, keeping on acceptable quality of results. Approximate Computing strategies, both at software and hardware level, balance computation quality and expended effort, in order to achieve application objectives and to maximize overall computational efficiency.

The design space of all possible configurations, for these kind of applications, is very huge and, therefore, it cannot be explored exhaustively. To achieve a full knowledge on both parameter values and corresponding metrics of interest (such as throughput, power consumption or output precision) is almost unfeasible and, therefore, we prefer approximate solutions.

This thesis has focused on the development of a framework, \textit{Agora}, that is able to drive online Design Space Exploration through an initial subset of configurations, in order to predict an application complete model through Machine Learning techniques. The result is used by an autotuner to dynamically adapt program execution with the best configuration that fulfills current goals and requirements. Main advantages of Agora are the elimination of any offline phase and design-time knowledge as well as the capability to manage multiple running applications at the same time.
