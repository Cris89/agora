\chapter{Conclusions and Future Works}\label{end}

\lettrine{W}{}\textit{e} have presented \textit{Agora}, a supporting framework designed to provide predicted complete model of tunable applications, including the whole list of parameter settings and related metric of interest performance. \textit{Agora} faces High Performance Computing application issues related to the problem of exploring design space in an exhaustive way, due to its significant dimension. Main goal is to collect information about a small subset of possible application configurations and, through this data and Machine Learning techniques, to predict general program behavior in all possible paratemer value combinations.

Unique \textit{Agora} feature is the ability to remotely drive Design Space Exploration phase among same executing applications at runtime, distributing all configurations to be explored in an efficient way, therefore every running program contributes to data collection and the entire workflow is considerably sped up; we remark that analysis is not done locally in every node of a possible parallel architecture, but it is accomplished outside, not consuming, in this way, node computational capacity, except for communications among \textit{Agora} modules, fulfilled by the lightweight MQTT messaging protocol.

In this thesis we show \textit{Agora} benefits, in terms of model prediction quality, execution times and ability to drive application executions in the reported experimental result, through multiple versions of a synthetic program with analytical metrics and a real scenario, using \textit{Swaptions} application from the PARSEC benchmark suite (\cite{bienia2008parsec}); we demonstrate that in several scenarios, even introducing strong noises, we are able to achieve very high model prediction quality and, having the possibility to use multiple executing nodes to explore application Design Space, we demonstrate how overall time strongly decreases with respect to an individual analysis with a single application: at the best of our knowledge, this is the first attempt to share Design Space Exploration as supervised by \textit{Agora}.

There are, certainly, several elements of our work that can be envisioned as future steps:

\begin{enumerate}

	\item in addition to implemented Machine Learning strategies (two versions of Generalized Linear Regression, see \ref{regrTransforms}), there can be added other techniques, in order to expand and to improve \textit{Agora} versatility; moreover, instead of entrusting to user the selection of Machine Learning strategy, the system could be able to analyze current problem and to choose itself best technique among the available ones in a proper way;

	\item after application model prediction, \textit{Agora} could continue to collect feedback information about program execution, in order to eventually update model and send again revised complete list of application configurations with related predicted performance in terms of metric of interest values;

	\item there could be added the possibility to specify a limit duration of Design Space Exploration phase: when time is up, \textit{AgoraRemoteAppHandler} module predicts application complete model with all information collected up to that moment;

	\item instead of specifying a priori application lapse for request (see \ref{clientReq}), \textit{AgoraLocalAppHandler} module could dynamically a\-dapt request frequency, according to previous execution times.

\end{enumerate}

We hope \textit{Agora} can contribute to the research on Design Space Exploration and Dynamic Autotuning of High Performance Computing applications in parallel architectures.
